{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterAnalisisDeSentimientosNLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SOxxz7q3Mo",
        "colab_type": "text"
      },
      "source": [
        "##Librerias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUCB2cyqula",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk > null\n",
        "!pip install sklearn > null\n",
        "!rm null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZb2M-_RrWQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feNT7M0NebqQ",
        "colab_type": "text"
      },
      "source": [
        "#Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYCOx8B_nSjs",
        "colab_type": "text"
      },
      "source": [
        "El dataset TASS se puede obtener a traves de [este enlace](http://www.sepln.org/workshops/tass/tass_data/download.php/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xSGA53Js0yh",
        "colab_type": "code",
        "outputId": "d6807959-d3e8-4ea6-da5c-824519065f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!head -n 20 general-train-tagged.xml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<tweets>\n",
            " <tweet>\n",
            "  <tweetid>142389495503925248</tweetid>\n",
            "  <user>ccifuentes</user>\n",
            "  <content><![CDATA[Salgo de #VeoTV , que día más largoooooo...]]></content>\n",
            "  <date>2011-12-02T00:47:55</date>\n",
            "  <lang>es</lang>\n",
            "  <sentiments>\n",
            "   <polarity><value>NONE</value><type>AGREEMENT</type></polarity>\n",
            "  </sentiments>\n",
            "  <topics>\n",
            "   <topic>otros</topic>\n",
            "  </topics>\n",
            " </tweet>\n",
            " <tweet>\n",
            "  <tweetid>142389933619945473</tweetid>\n",
            "  <user>CarmendelRiego</user>\n",
            "  <content><![CDATA[@PauladeLasHeras No te libraras de ayudar me/nos. Besos y gracias]]></content>\n",
            "  <date>2011-12-02T00:49:40</date>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjlp6iyyrZ43",
        "colab_type": "text"
      },
      "source": [
        "Como podemos ver, el dataset esta en formato xml, para utilizarlo lo transformaremos a csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYVe3RI-uqzm",
        "colab_type": "text"
      },
      "source": [
        "##general-train-tagged.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnR4Az5qT9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    general_tweets_corpus_train = pd.read_csv('general-train-tagged.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('general-train-tagged.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    general_tweets_corpus_train = pd.DataFrame(columns=('content', 'polarity', 'agreement'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity', 'agreement'], [tweet.content.text, tweet.sentiments.polarity.value.text, tweet.sentiments.polarity.type.text]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        general_tweets_corpus_train = general_tweets_corpus_train.append(row_s)\n",
        "    general_tweets_corpus_train.to_csv('general-tweets-train-tagged.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzj-dGFvzMwg",
        "colab_type": "code",
        "outputId": "c14e6918-0778-4b0b-e214-199c6b67e156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "general_tweets_corpus_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Salgo de #VeoTV , que día más largoooooo...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@PauladeLasHeras No te libraras de ayudar me/nos. Besos y gracias</td>\n",
              "      <td>NEU</td>\n",
              "      <td>DISAGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@marodriguezb Gracias MAR</td>\n",
              "      <td>P</td>\n",
              "      <td>AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Off pensando en el regalito Sinde, la que se va de la SGAE cuando se van sus corruptos. Intento no sacar conclusiones (lo intento)</td>\n",
              "      <td>N+</td>\n",
              "      <td>AGREEMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Conozco a alguien q es adicto al drama! Ja ja ja te suena d algo!</td>\n",
              "      <td>P+</td>\n",
              "      <td>AGREEMENT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                              content  ...     agreement\n",
              "0                                                                                         Salgo de #VeoTV , que día más largoooooo...  ...     AGREEMENT\n",
              "1                                                                   @PauladeLasHeras No te libraras de ayudar me/nos. Besos y gracias  ...  DISAGREEMENT\n",
              "2                                                                                                           @marodriguezb Gracias MAR  ...     AGREEMENT\n",
              "3  Off pensando en el regalito Sinde, la que se va de la SGAE cuando se van sus corruptos. Intento no sacar conclusiones (lo intento)  ...     AGREEMENT\n",
              "4                                                                   Conozco a alguien q es adicto al drama! Ja ja ja te suena d algo!  ...     AGREEMENT\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9vbptodlioT",
        "colab_type": "text"
      },
      "source": [
        "##general-test-tagged-3l.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMREFU_8euR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    general_test_tagged = pd.read_csv('general-test-tagged-3l.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('general-test-tagged-3l.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    general_test_tagged = pd.DataFrame(columns=('content', 'polarity'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity'], [tweet.content.text, tweet.sentiments.polarity.value.text]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        general_test_tagged = general_test_tagged.append(row_s)\n",
        "    general_test_tagged.to_csv('general-test-tagged-3l.csv', index=False, encoding='utf-8')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-yVoncomOD3",
        "colab_type": "code",
        "outputId": "1c2286a7-ed24-40d0-e7b9-ad79a5ebd49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "general_test_tagged.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Portada 'Público', viernes. Fabra al banquillo por 'orden' del Supremo; Wikileaks 'retrata' a 160 empresas espías. http://t.co/YtpRU0fd</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Grande! RT @veronicacalderon \"El periodista es alguien que quiere contar la realidad, pero no vive en ella\" via @galtares</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gonzalo Altozano tras la presentación de su libro 101 españoles y Dios. Divertido, emocionante y brillante. http://t.co/4BdljMhB</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mañana en Gaceta: TVE, la que pagamos tú y yo, culpa a una becaria de su falsa información sobre el cierre de @gaceta</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Qué envidia “@mfcastineiras: Pedro mañana x la mañana me voy a Paris, cuando esté por la almendra parisina recordaré #Elprimernaufragio.”</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                     content polarity\n",
              "0    Portada 'Público', viernes. Fabra al banquillo por 'orden' del Supremo; Wikileaks 'retrata' a 160 empresas espías. http://t.co/YtpRU0fd        N\n",
              "1                  Grande! RT @veronicacalderon \"El periodista es alguien que quiere contar la realidad, pero no vive en ella\" via @galtares     NONE\n",
              "2           Gonzalo Altozano tras la presentación de su libro 101 españoles y Dios. Divertido, emocionante y brillante. http://t.co/4BdljMhB        P\n",
              "3                      Mañana en Gaceta: TVE, la que pagamos tú y yo, culpa a una becaria de su falsa información sobre el cierre de @gaceta        N\n",
              "4  Qué envidia “@mfcastineiras: Pedro mañana x la mañana me voy a Paris, cuando esté por la almendra parisina recordaré #Elprimernaufragio.”     NONE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0yVCQbXvAgJ",
        "colab_type": "text"
      },
      "source": [
        "##stompol-train-tagged.xml\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8SRY_Tnt5ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    stompol_tweets_corpus_train = pd.read_csv('stompol-train-tagged.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('stompol-train-tagged.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    stompol_tweets_corpus_train = pd.DataFrame(columns=('content', 'polarity'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity', 'agreement'], [' '.join(list(tweet.itertext())), tweet.sentiment.get('polarity')]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        stompol_tweets_corpus_train = stompol_tweets_corpus_train.append(row_s)\n",
        "    stompol_tweets_corpus_train.to_csv('stompol-tweets-train-tagged.csv', index=False, encoding='utf-8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yycFiBCSrVpx",
        "colab_type": "code",
        "outputId": "bf9f9dc1-bfa9-46e1-ea2e-35d12a6899be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "stompol_tweets_corpus_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Diga cuanto nos van a costar las  autovías  de sus amiguetes ¿4500 millones o más ?  @EsperanzAguirre @PPopular</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@lhermoso_ @sanchezcastejon  #DobleMoral  Castilla antes que Aragón...</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@PSOE  @sanchezcastejon Me hace mucha gracia que esa afirmación la haga el PSOE</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Para que todo el mundo lo tengo claro ....  @CsAlzira_   https://t.co/kcDxbhu3Ha</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Albert_Rivera  y  @CiudadanosCs  saben q este país es progresista pero q se arruga y vota centro. Discurso moderado y electoralista.</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                 content polarity\n",
              "0                        Diga cuanto nos van a costar las  autovías  de sus amiguetes ¿4500 millones o más ?  @EsperanzAguirre @PPopular        N\n",
              "1                                                                 @lhermoso_ @sanchezcastejon  #DobleMoral  Castilla antes que Aragón...        N\n",
              "2                                                        @PSOE  @sanchezcastejon Me hace mucha gracia que esa afirmación la haga el PSOE        N\n",
              "3                                                       Para que todo el mundo lo tengo claro ....  @CsAlzira_   https://t.co/kcDxbhu3Ha      NEU\n",
              "4  @Albert_Rivera  y  @CiudadanosCs  saben q este país es progresista pero q se arruga y vota centro. Discurso moderado y electoralista.        N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LSVaLOM0qPz",
        "colab_type": "text"
      },
      "source": [
        "##stompol-test-tagged.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmcDRTJEzkZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    stompol_tweets_corpus_test = pd.read_csv('stompol-test-tagged.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('stompol-test-tagged.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    stompol_tweets_corpus_test = pd.DataFrame(columns=('content', 'polarity'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity', 'agreement'], [' '.join(list(tweet.itertext())), tweet.sentiment.get('polarity')]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        stompol_tweets_corpus_test = stompol_tweets_corpus_test.append(row_s)\n",
        "    stompol_tweets_corpus_test.to_csv('stompol-tweets-test-tagged.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW1iC9hDz9N_",
        "colab_type": "code",
        "outputId": "2c30e6cc-9651-4bc3-92fd-8cbac3437401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "stompol_tweets_corpus_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mapa con el \"batiburrillo\" d partidos que ha absorbido  @CiudadanosCs  frente a  @UPyD  que se mantiene #Libres @mpalcedo http://t.co/sYQYv0zSjz</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Leyendo programas de  @CiudadanosCs   y  @ahorapodemos   me encuentro exactamente lo mismo: reestructuración ordenada de la deuda</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Buenos días, lo que está ocurriendo con el barco ruso es una ínfima muestra de lo que pudo suceder con las prospecciones de  @PPopular .</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@CambiarMadrid_ @AhoraGetafe  la verdadera  @iunida  http://t.co/NJ8cL7wUaL</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>En el  @PSOE  saben que tendrán que pactar, no saben con quien, si quieren gobernar</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                            content polarity\n",
              "0  Mapa con el \"batiburrillo\" d partidos que ha absorbido  @CiudadanosCs  frente a  @UPyD  que se mantiene #Libres @mpalcedo http://t.co/sYQYv0zSjz        N\n",
              "1                 Leyendo programas de  @CiudadanosCs   y  @ahorapodemos   me encuentro exactamente lo mismo: reestructuración ordenada de la deuda      NEU\n",
              "2          Buenos días, lo que está ocurriendo con el barco ruso es una ínfima muestra de lo que pudo suceder con las prospecciones de  @PPopular .        N\n",
              "3                                                                       @CambiarMadrid_ @AhoraGetafe  la verdadera  @iunida  http://t.co/NJ8cL7wUaL      NEU\n",
              "4                                                               En el  @PSOE  saben que tendrán que pactar, no saben con quien, si quieren gobernar      NEU"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGDOjq5Y0cJG",
        "colab_type": "text"
      },
      "source": [
        "##socialtv-test-tagged.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idNsTjHG0Hc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    social_tweets_corpus_test = pd.read_csv('socialtv-test-tagged.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('socialtv-test-tagged.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    social_tweets_corpus_test = pd.DataFrame(columns=('content', 'polarity'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity', 'agreement'], [' '.join(list(tweet.itertext())), tweet.sentiment.get('polarity')]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        social_tweets_corpus_test = social_tweets_corpus_test.append(row_s)\n",
        "    social_tweets_corpus_test.to_csv('socialtv-tweets-test-tagged.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSvNa3Aq0wVH",
        "colab_type": "code",
        "outputId": "075aad33-3bff-4d60-b0fd-bd3e5ae57f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "social_tweets_corpus_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La culpa es del  Tata  ... Jajajajajajjajajaja</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>El  Barça  tiene que hacer muchos cambios, empezando por la directiva.</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Repito, jugadores que deben salir si o si:  Pinto ,  Alves ,  Mascherano ,  Adriano ,  Song ,  Fabregas ,  Alexis  y  Neymar .</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Recien me entero que  messi  estaba jugando!</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>con dos cojones han ganado y sin  Cristiano .</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                          content polarity\n",
              "0                                                                                  La culpa es del  Tata  ... Jajajajajajjajajaja        N\n",
              "1                                                          El  Barça  tiene que hacer muchos cambios, empezando por la directiva.        N\n",
              "2  Repito, jugadores que deben salir si o si:  Pinto ,  Alves ,  Mascherano ,  Adriano ,  Song ,  Fabregas ,  Alexis  y  Neymar .      NEU\n",
              "3                                                                                    Recien me entero que  messi  estaba jugando!        N\n",
              "4                                                                                   con dos cojones han ganado y sin  Cristiano .      NEU"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_86EM9f1Fso",
        "colab_type": "text"
      },
      "source": [
        "##socialtv-tweets-train-tagged.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk32ohB1Bf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    social_tweets_corpus_train = pd.read_csv('socialtv-train-tagged.csv', encoding='utf-8')\n",
        "except:\n",
        "\n",
        "    from lxml import objectify\n",
        "    xml = objectify.parse(open('socialtv-train-tagged.xml', encoding=\"utf8\"))\n",
        "    #sample tweet object\n",
        "    root = xml.getroot()\n",
        "    social_tweets_corpus_train = pd.DataFrame(columns=('content', 'polarity'))\n",
        "    tweets = root.getchildren()\n",
        "    for i in range(0,len(tweets)):\n",
        "        tweet = tweets[i]\n",
        "        row = dict(zip(['content', 'polarity', 'agreement'], [' '.join(list(tweet.itertext())), tweet.sentiment.get('polarity')]))\n",
        "        row_s = pd.Series(row)\n",
        "        row_s.name = i\n",
        "        social_tweets_corpus_train = social_tweets_corpus_train.append(row_s)\n",
        "    social_tweets_corpus_train.to_csv('socialtv-tweets-train-tagged.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSPYrcLL1Or4",
        "colab_type": "code",
        "outputId": "068b9832-d0d2-4aca-d12a-f8da4e59f8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "social_tweets_corpus_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Los que esta noche van a la redonda a celebrar la victoria  del  Real Madrid  les espero para cuando suba el  @realmurciacfsad  a primera.</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Diooooos que careron de  gareth  madreeeeee ahí están los jugadores importantes decidiendo  partidos  vamos coñoooooooo jajaja hala  madrid</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ganó el mejor.  @realmadrid    #CopaRelRey    #FinalCopaRelRey</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@realmadrid  Felicidades!!! ? Gracias por alegrarme la tarde!!! ??? *Aplausos* #Feliz</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@titelas Mañana  Bale  en naranja</td>\n",
              "      <td>NEU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                       content polarity\n",
              "0   Los que esta noche van a la redonda a celebrar la victoria  del  Real Madrid  les espero para cuando suba el  @realmurciacfsad  a primera.        P\n",
              "1  Diooooos que careron de  gareth  madreeeeee ahí están los jugadores importantes decidiendo  partidos  vamos coñoooooooo jajaja hala  madrid        P\n",
              "2                                                                               Ganó el mejor.  @realmadrid    #CopaRelRey    #FinalCopaRelRey        P\n",
              "3                                                        @realmadrid  Felicidades!!! ? Gracias por alegrarme la tarde!!! ??? *Aplausos* #Feliz        P\n",
              "4                                                                                                            @titelas Mañana  Bale  en naranja      NEU"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhmW869Z1OKV",
        "colab_type": "text"
      },
      "source": [
        "##Union y limpiza de todos los dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1yyQxZV1ahA",
        "colab_type": "code",
        "outputId": "58948a80-21f0-400f-a5fd-094cba6b85a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "tweets_corpus = pd.concat([\n",
        "        social_tweets_corpus_train,\n",
        "        social_tweets_corpus_test,\n",
        "        stompol_tweets_corpus_test,\n",
        "        stompol_tweets_corpus_train,\n",
        "        general_tweets_corpus_train,\n",
        "        general_test_tagged\n",
        "        \n",
        "    ])\n",
        "tweets_corpus = tweets_corpus.query('agreement != \"DISAGREEMENT\" and polarity != \"NONE\"')\n",
        "tweets_corpus = tweets_corpus[-tweets_corpus.content.str.contains('^http.*$')]\n",
        "\n",
        "tweets_corpus = tweets_corpus[tweets_corpus.polarity != 'NEU']\n",
        "tweets_corpus['polarity_bin'] = 0\n",
        "tweets_corpus.polarity_bin[tweets_corpus.polarity.isin(['P', 'P+'])] = 1\n",
        "tweets_corpus.polarity_bin.value_counts(normalize=True)\n",
        "\n",
        "tweets_corpus.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45745, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFNZoBSt3Jgc",
        "colab_type": "code",
        "outputId": "7cec07ba-a823-436c-e9c6-812de1da14d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "tweets_corpus.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agreement</th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "      <th>polarity_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44776</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Y el ganador de un concurso de bebedores de Cerveza en La Granja de Bilbao. ¿Hace falta entrenarse? \"No, sólo ser un bocazas y estar triste\"</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41510</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Ahora si ;-)) muchas felicidades @FdoFrances ;-))</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Bono haciendo de conciliador!! Es sensato, aunque hubiera estado bien escucharlo antes.</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6866</th>\n",
              "      <td>AGREEMENT</td>\n",
              "      <td>Muchas gracias! RT @sangaruz: @sevillajordi Me ha gustado su intervención en radio nacional</td>\n",
              "      <td>P+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2265</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Mario Vaquerizo dice que @EsperanzAguirre \"es una buena política\" http://t.co/Qv5obrAr (via @digitaldemadrid)</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20483</th>\n",
              "      <td>NaN</td>\n",
              "      <td>“@quediario: La muerte de Fraga y las novedades del hundimiento del costa Concordia. Portada del diario Qué! del 16/01 http://t.co/My7qXv0h”</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Oleee mi  Real Madrid  que grandes somos  @halamadrid   @FinalCopaDelRey</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51663</th>\n",
              "      <td>NaN</td>\n",
              "      <td>La velocidad extrema tanto en los movimientos como en la vida misma trata de imitar de forma absurda, me parece, la vida eterna.</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38678</th>\n",
              "      <td>NaN</td>\n",
              "      <td>En teoría, la comparecencia del Ministro del Interior esta tarde en el #Congreso es para hablar de ETA (detenciones y enmienda).</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>AGREEMENT</td>\n",
              "      <td>Los médicos dejan la Comunidad Valenciana http://t.co/vSwXAbOT</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       agreement  ... polarity_bin\n",
              "44776        NaN  ...            0\n",
              "41510        NaN  ...            1\n",
              "1912         NaN  ...            1\n",
              "6866   AGREEMENT  ...            1\n",
              "2265         NaN  ...            1\n",
              "20483        NaN  ...            0\n",
              "1342         NaN  ...            1\n",
              "51663        NaN  ...            0\n",
              "38678        NaN  ...            0\n",
              "1755   AGREEMENT  ...            0\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf2FuFS34gDQ",
        "colab_type": "text"
      },
      "source": [
        "#Tokenizing & Stemming\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVnV0wjK5Sin",
        "colab_type": "text"
      },
      "source": [
        "Informacion sobre [Tokenizing](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n",
        "\n",
        "Los Stemmers eliminan los afijos morfológicos de las palabras, dejando solo la su raíz o (en inglés) a un stem\n",
        "![texto alternativo](https://i0.wp.com/trevorfox.com/wp-content/uploads/2018/07/stemming-example.png?resize=768%2C576&ssl=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv44_ZLY56oH",
        "colab_type": "code",
        "outputId": "6bf4d253-fccf-4f4c-b033-c63df8111aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\") \n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "spanish_stopwords = stopwords.words('spanish')\n",
        "spanish_stopwords[0:15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'la',\n",
              " 'que',\n",
              " 'el',\n",
              " 'en',\n",
              " 'y',\n",
              " 'a',\n",
              " 'los',\n",
              " 'del',\n",
              " 'se',\n",
              " 'las',\n",
              " 'por',\n",
              " 'un',\n",
              " 'para',\n",
              " 'con']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-7UWXG6RVC",
        "colab_type": "code",
        "outputId": "dfd8dc53-bcb7-44f0-a050-a3bd5355c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from string import punctuation\n",
        "non_words = list(punctuation)\n",
        "\n",
        "non_words.extend(['¿', '¡']) #Añadimos los signos de puntuacion españoles\n",
        "non_words.extend(map(str,range(10))) #Los numeros 0 - 9\n",
        "non_words[0:15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Vsw97o6o4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer       \n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for item in tokens:\n",
        "        stemmed.append(stemmer.stem(item))\n",
        "    return stemmed\n",
        "\n",
        "def tokenize(text):\n",
        "    # remove non letters\n",
        "    text = ''.join([c for c in text if c not in non_words])\n",
        "    # tokenize\n",
        "    tokens =  word_tokenize(text)\n",
        "\n",
        "    # stem\n",
        "    try:\n",
        "        stems = stem_tokens(tokens, stemmer)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(text)\n",
        "        stems = ['']\n",
        "    return stems"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3unb2dg8H1X",
        "colab_type": "text"
      },
      "source": [
        "#Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyZQoMEc8HbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "                analyzer = 'word',\n",
        "                tokenizer = tokenize,\n",
        "                lowercase = True,\n",
        "                stop_words = spanish_stopwords)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('cls', LinearSVC()),\n",
        "])\n",
        "\n",
        "\n",
        "parameters = {\n",
        "    'vect__max_df': (0.5, 1.9),\n",
        "    'vect__min_df': (10, 20,50),\n",
        "    'vect__max_features': (500, 1000),\n",
        "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
        "    'cls__C': (0.2, 0.5, 0.7),\n",
        "    'cls__loss': ('hinge', 'squared_hinge'),\n",
        "    'cls__max_iter': (500, 1000)\n",
        "}\n",
        "\n",
        "try:\n",
        "  from sklearn.externals import joblib\n",
        "  grid_search = joblib.load(\"grid_search.pkl\")\n",
        "except:  \n",
        "  grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1 , scoring='roc_auc', verbose=10 )\n",
        "  grid_search.fit(tweets_corpus.content, tweets_corpus.polarity_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyyTB6w-WFMl",
        "colab_type": "code",
        "outputId": "c5a22ac2-b7f8-4805-8417-4d9699a85b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cls__C': 0.2,\n",
              " 'cls__loss': 'hinge',\n",
              " 'cls__max_iter': 500,\n",
              " 'vect__max_df': 0.5,\n",
              " 'vect__max_features': 1000,\n",
              " 'vect__min_df': 10,\n",
              " 'vect__ngram_range': (1, 1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyir7khoWP_y",
        "colab_type": "text"
      },
      "source": [
        "Guardar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9jOVVcUWPG4",
        "colab_type": "code",
        "outputId": "6d469b2e-aaf6-4daf-a352-9ff472c08a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "joblib.dump(grid_search, 'grid_search.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['grid_search.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyQuLXeNXDC3",
        "colab_type": "text"
      },
      "source": [
        "# predicciones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTwoadoKXjHY",
        "colab_type": "text"
      },
      "source": [
        "##cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvKTvvJXE9S",
        "colab_type": "code",
        "outputId": "c4351689-30f2-4446-eb07-e942c555c7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "model = LinearSVC(C=.2, loss='hinge',max_iter=500,multi_class='ovr',\n",
        "              random_state=None,\n",
        "              penalty='l2',\n",
        "              tol=0.0001\n",
        ")\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    analyzer = 'word',\n",
        "    tokenizer = tokenize,\n",
        "    lowercase = True,\n",
        "    stop_words = spanish_stopwords,\n",
        "    max_df = 0.5,\n",
        "    max_features=1000,\n",
        "    min_df = 10,\n",
        "    ngram_range=(1, 1)\n",
        ")\n",
        "\n",
        "corpus_data_features = vectorizer.fit_transform(tweets_corpus.content)\n",
        "corpus_data_features_nd = corpus_data_features.toarray()\n",
        "scores = cross_val_score(\n",
        "    model,\n",
        "    corpus_data_features_nd[0:len(tweets_corpus)],\n",
        "    y=tweets_corpus.polarity_bin,\n",
        "    scoring='roc_auc',\n",
        "    cv=5\n",
        "  )\n",
        "\n",
        "scores.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9199494710076417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEHy9bPPXol1",
        "colab_type": "text"
      },
      "source": [
        "##Prediccion de polaridad\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6fz5E2CaFVk",
        "colab_type": "code",
        "outputId": "6cf2d3bf-7061-4595-a609-72bae9168242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('cls', LinearSVC(C=.2, loss='hinge',max_iter=1000,multi_class='ovr',\n",
        "             random_state=None,\n",
        "             penalty='l2',\n",
        "             tol=0.0001\n",
        "             )),\n",
        "])\n",
        "\n",
        "#pipeline.fit(tweets_corpus.content, tweets_corpus.polarity_bin)\n",
        "pipeline.fit(tweets_corpus.content, tweets_corpus.polarity_bin)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=0.5,\n",
              "                                 max_features=1000, min_df=10,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=['de', 'la', 'que', 'el', 'en', 'y',\n",
              "                                             'a', 'los', 'del', 'se', 'las',\n",
              "                                             'por', 'un', 'para', 'con', 'no'...\n",
              "                                             'o', 'este', 'sí', 'porque', ...],\n",
              "                                 strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize at 0x7f146c39ba60>,\n",
              "                                 vocabulary=None)),\n",
              "                ('cls',\n",
              "                 LinearSVC(C=0.2, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
              "                           penalty='l2', random_state=None, tol=0.0001,\n",
              "                           verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4g6pgQ6a0oz",
        "colab_type": "code",
        "outputId": "67bdd153-e344-4643-f3af-ee3abb7be962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tweets = pd.read_csv('tweets.csv', encoding='utf-8')\n",
        "tweets[\"polarity\"] = pipeline.predict(tweets.Tweet)\n",
        "pd.options.display.max_colwidth = 1000\n",
        "tweets[[\"Tweet\",\"polarity\"]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ahora mismo si tuviese una pistola me pegaba un tiro sin pensarlo.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hola.   Visto 05:36.   Ms que Visto 05:38.   Ignorado 05:41.   No le importas 5:58.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Buenas noches a todos... Fav ;) juju</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JAJAJA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Salimos para a corua :)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>No va desencaminado!! #MundialBrasil2014 http://t.co/yhDfeN3Z6k</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@Maikykrmusic Te quiero mucho mucho mi vida &amp;lt;3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Oh maana tengo Edu.Fisica</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@AlexLuna_72 calla, alexis primo dejate las tonterias que todo pasa y vienen cosas mejores Buenas noches manico</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@dayi_9926 fback cute acc</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Buenas noches gente ;) http://t.co/F6gjnYNMpi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Su Mirada &amp;lt;3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>La cara de la vieja, jajajajajajajajaja</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Uh es re temprano todava .!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Eso si te gusta .....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Me lleno de notificaciones la chabona, sal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Buena noche de entrenamiento musical... toca dormir ! Buenas noches a todos*</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>O sea me tuve que sentar con Eliseo en taller, mala suerte la ma :p -.-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nos tratamos tan bien con Sagardia :3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>@DianaYulissa23 no hay nada mejor que me recibas cuando venga de trabajar ojal sean ya las 7!!!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>No le sale, como al otro, jajaja</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Manteca  http://t.co/G7gMLjH22G</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Que lindo es ver a mi papa y a mi mama mas enamorados que nunca &amp;lt;3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>@germansagardia1 Maaal, milagro seria si estamos un da sin decimos algo malo, jajajajaja eso si seria un milagro :3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Odio esa propaganda, la verdad no me la banco -.- la odio -.-</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>@germansagardia1 Jajajajaa, bue a alguien tenia que correr, a :3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Olvidarte es imposible -8-</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Mam se re durmi :3, noc si asustarla o no :33 Jajajaja</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>https://t.co/uf5AR98LOZ Que Grande</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>@germansagardia1 Jajajaja, es que sos el ms dbil enano..</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>@Juliacastillo00 felicidadesss  espero verte en el conciertoo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>@PeluconPisaLodo Por primera vez en nuestras vidas veremos una Luna roja en nuestro cielo, y la caravana de emelec aun no llega!!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>(Otro posible agujero negro) La UDEF investiga a la Junta de Andaluca por otro fraude masivo de 2.000 millones http://t.co/0xMir9gkE4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>@melany_sc ajjajajajja era para que se rian un rato, ya que ni la luna sale :(</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>@majocedillo_12 Despus que uno es el que se porta mal !!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Jajajaja vamos a por el martes http://t.co/9R6os8kI8j</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Buenoss diasss por la maanaa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Ya ces Luna, no te hagas de rogar ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>@melany_sc ajajjaaa si por que esa luna mucho se hace de rogar :( me duermo y no sale jajja :( :(</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>A estas horas de la maana ya he echado 2 broncas telefnicas. Normalmente soy una persona encantadora. Os lo juro</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>@bryanvalles96 Mira Luna Putaa, voy a desvelarme porti, y sinoo te veoo roja, ni creaas que el proximo ao voy a desvelarme, veras cdtm !!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>Paisaje idlico. http://t.co/A9RQMmUZeD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Y ami que no me gusta esperar ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Nubes de algodn. http://t.co/jogMNifEMC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Nubes de algodn. http://t.co/mFsbByjCuX</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>Te has ganado mi cario incondicional</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>Buenos das mundo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>\"@Accionpoetadice: http://t.co/zdVSNtXDhX\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>Hoy toca una de playa con los putos guatemaltecos y compaa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>Beirut. Lbano. http://t.co/EAUdAL15Q5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>@melany_sc ajjajaj yo llevo horas y horas aki,  y nada :( ya mismo nos dormimos y no vemos nada :(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Buenos das,  RT @josemmol : HUERTA DE ABAJO #MolinadeSegura AMANECER DE HOY http://t.co/vMODAp5Xx7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Luna sale, as no te pongas en roja, pero sale, si ....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>@mariajo_moreno Y si la oracin es imperativa? Por ejemplo: \"Pablito, cmete las espinacas o no hay postre.\" \"Lzaro, levantarte y anda.\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Joffrey rest in peace</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>Bien + RT @RosaRodaNews : Concejala de Cultura en #MolinadeSegura, @MariolaRobles se pondr al frente del Instituto de Turismo de la regin.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Tener que despertarme a estas horas para hacerme una puta analtica JODE.  Buenos Das &amp;lt;3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>Rallada matutina</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>Buenos das #tuiteros</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>http://t.co/Q65k6lfYFw</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>173 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                          Tweet  polarity\n",
              "0                                                                            Ahora mismo si tuviese una pistola me pegaba un tiro sin pensarlo.         0\n",
              "1                                                           Hola.   Visto 05:36.   Ms que Visto 05:38.   Ignorado 05:41.   No le importas 5:58.         1\n",
              "2                                                                                                          Buenas noches a todos... Fav ;) juju         1\n",
              "3                                                                                                                                        JAJAJA         1\n",
              "4                                                                                                                       Salimos para a corua :)         1\n",
              "5                                                                               No va desencaminado!! #MundialBrasil2014 http://t.co/yhDfeN3Z6k         1\n",
              "6                                                                                             @Maikykrmusic Te quiero mucho mucho mi vida &lt;3         1\n",
              "7                                                                                                                     Oh maana tengo Edu.Fisica         1\n",
              "8                               @AlexLuna_72 calla, alexis primo dejate las tonterias que todo pasa y vienen cosas mejores Buenas noches manico         1\n",
              "9                                                                                                                     @dayi_9926 fback cute acc         1\n",
              "10                                                                                                Buenas noches gente ;) http://t.co/F6gjnYNMpi         1\n",
              "11                                                                                                                              Su Mirada &lt;3         1\n",
              "12                                                                                                      La cara de la vieja, jajajajajajajajaja         0\n",
              "13                                                                                                                  Uh es re temprano todava .!         0\n",
              "14                                                                                                                        Eso si te gusta .....         1\n",
              "15                                                                                                   Me lleno de notificaciones la chabona, sal         1\n",
              "16                                                                 Buena noche de entrenamiento musical... toca dormir ! Buenas noches a todos*         1\n",
              "17                                                                      O sea me tuve que sentar con Eliseo en taller, mala suerte la ma :p -.-         0\n",
              "18                                                                                                        Nos tratamos tan bien con Sagardia :3         1\n",
              "19                                            @DianaYulissa23 no hay nada mejor que me recibas cuando venga de trabajar ojal sean ya las 7!!!!!         1\n",
              "20                                                                                                             No le sale, como al otro, jajaja         1\n",
              "21                                                                                                              Manteca  http://t.co/G7gMLjH22G         1\n",
              "22                                                                        Que lindo es ver a mi papa y a mi mama mas enamorados que nunca &lt;3         1\n",
              "23                          @germansagardia1 Maaal, milagro seria si estamos un da sin decimos algo malo, jajajajaja eso si seria un milagro :3         0\n",
              "24                                                                                Odio esa propaganda, la verdad no me la banco -.- la odio -.-         1\n",
              "25                                                                             @germansagardia1 Jajajajaa, bue a alguien tenia que correr, a :3         0\n",
              "26                                                                                                                   Olvidarte es imposible -8-         0\n",
              "27                                                                                       Mam se re durmi :3, noc si asustarla o no :33 Jajajaja         1\n",
              "28                                                                                                           https://t.co/uf5AR98LOZ Que Grande         1\n",
              "29                                                                                     @germansagardia1 Jajajaja, es que sos el ms dbil enano..         1\n",
              "..                                                                                                                                          ...       ...\n",
              "143                                                                              @Juliacastillo00 felicidadesss  espero verte en el conciertoo          1\n",
              "144         @PeluconPisaLodo Por primera vez en nuestras vidas veremos una Luna roja en nuestro cielo, y la caravana de emelec aun no llega!!!!         1\n",
              "145       (Otro posible agujero negro) La UDEF investiga a la Junta de Andaluca por otro fraude masivo de 2.000 millones http://t.co/0xMir9gkE4         0\n",
              "146                                                              @melany_sc ajjajajajja era para que se rian un rato, ya que ni la luna sale :(         1\n",
              "147                                                                                    @majocedillo_12 Despus que uno es el que se porta mal !!         0\n",
              "148                                                                                       Jajajaja vamos a por el martes http://t.co/9R6os8kI8j         1\n",
              "149                                                                                                                Buenoss diasss por la maanaa         1\n",
              "150                                                                                                       Ya ces Luna, no te hagas de rogar ...         1\n",
              "151                                           @melany_sc ajajjaaa si por que esa luna mucho se hace de rogar :( me duermo y no sale jajja :( :(         1\n",
              "152                            A estas horas de la maana ya he echado 2 broncas telefnicas. Normalmente soy una persona encantadora. Os lo juro         1\n",
              "153  @bryanvalles96 Mira Luna Putaa, voy a desvelarme porti, y sinoo te veoo roja, ni creaas que el proximo ao voy a desvelarme, veras cdtm !!!         1\n",
              "154                                                                                                      Paisaje idlico. http://t.co/A9RQMmUZeD         1\n",
              "155                                                                                                           Y ami que no me gusta esperar ...         1\n",
              "156                                                                                                     Nubes de algodn. http://t.co/jogMNifEMC         1\n",
              "157                                                                                                     Nubes de algodn. http://t.co/mFsbByjCuX         1\n",
              "158                                                                                                        Te has ganado mi cario incondicional         1\n",
              "159                                                                                                                            Buenos das mundo         1\n",
              "160                                                                                                  \"@Accionpoetadice: http://t.co/zdVSNtXDhX\"         1\n",
              "161                                                                                  Hoy toca una de playa con los putos guatemaltecos y compaa         0\n",
              "162                                                                                                       Beirut. Lbano. http://t.co/EAUdAL15Q5         1\n",
              "163                                          @melany_sc ajjajaj yo llevo horas y horas aki,  y nada :( ya mismo nos dormimos y no vemos nada :(         0\n",
              "164                                          Buenos das,  RT @josemmol : HUERTA DE ABAJO #MolinadeSegura AMANECER DE HOY http://t.co/vMODAp5Xx7         1\n",
              "165                                                                                      Luna sale, as no te pongas en roja, pero sale, si ....         1\n",
              "166      @mariajo_moreno Y si la oracin es imperativa? Por ejemplo: \"Pablito, cmete las espinacas o no hay postre.\" \"Lzaro, levantarte y anda.\"         1\n",
              "167                                                                                                                       Joffrey rest in peace         0\n",
              "168  Bien + RT @RosaRodaNews : Concejala de Cultura en #MolinadeSegura, @MariolaRobles se pondr al frente del Instituto de Turismo de la regin.         1\n",
              "169                                                  Tener que despertarme a estas horas para hacerme una puta analtica JODE.  Buenos Das &lt;3         1\n",
              "170                                                                                                                            Rallada matutina         1\n",
              "171                                                                                                                        Buenos das #tuiteros         1\n",
              "172                                                                                                                      http://t.co/Q65k6lfYFw         1\n",
              "\n",
              "[173 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSKPeuhdyybA",
        "colab_type": "text"
      },
      "source": [
        "#Agradecimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YbCWjZay_H-",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/\n",
        "\n",
        "https://www.pybonacci.org/2015/11/24/como-hacer-analisis-de-sentimiento-en-espanol-2/\n",
        "\n",
        "http://blog.manugarri.com/sentiment-analysis-in-spanish/\n",
        "\n",
        "https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
        "\n",
        "http://www.sepln.org/sepln"
      ]
    }
  ]
}